{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd4b8920-0e35-4c8f-93bd-6c21ac6aa1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import mediapipe as mp\n",
    "# import numpy as np\n",
    "\n",
    "# # Initialize mediapipe pose and selfie segmentation\n",
    "# mp_pose = mp.solutions.pose\n",
    "# mp_selfie_segmentation = mp.solutions.selfie_segmentation\n",
    "# pose = mp_pose.Pose()\n",
    "# selfie_segmentation = mp_selfie_segmentation.SelfieSegmentation(model_selection=1)\n",
    "\n",
    "# # Initialize drawing utilities\n",
    "# mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# # Start video capture\n",
    "# cap = cv2.VideoCapture(r\"C:\\Users\\PRAJES DAS\\Downloads\\video6.mp4\")\n",
    "\n",
    "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "# out = cv2.VideoWriter('output5.mp4', fourcc, fps, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "# def draw_3d_landmarks_on_box(image, landmarks, box_position):\n",
    "#     h, w, _ = image.shape\n",
    "#     box_w, box_h = 200, 200  # Size of the box\n",
    "#     box_x, box_y = box_position\n",
    "    \n",
    "#     # the box\n",
    "#     box_image = np.ones((box_h, box_w, 3), dtype=np.uint8) * np.array([252, 3, 161], dtype=np.uint8)\n",
    "    \n",
    "#     for landmark in landmarks:\n",
    "#         x = int(landmark.x * box_w)\n",
    "#         y = int(landmark.y * box_h)\n",
    "#         z = int(landmark.z * box_w)  \n",
    "#         cv2.circle(box_image, (x, y), 3, (3, 252, 206), -1)\n",
    "\n",
    "#     # Overlay the box image on the main image\n",
    "#     image[box_y:box_y+box_h, box_x:box_x+box_w] = box_image\n",
    "\n",
    "# def draw_analytics_overlay(landmarks, overlay_size=(300, 150)):\n",
    "#     overlay_image = np.ones((overlay_size[1], overlay_size[0], 3), dtype=np.uint8) * np.array([252, 3, 161], dtype=np.uint8)\n",
    "#     text_y = 20\n",
    "\n",
    "#     ## Posture Analysis\n",
    "#     # Calculate angle between shoulder, elbow, and wrist\n",
    "#     shoulder = np.array([landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "#                          landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y,\n",
    "#                          landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].z])\n",
    "\n",
    "#     elbow = np.array([landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "#                       landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y,\n",
    "#                       landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].z])\n",
    "\n",
    "#     wrist = np.array([landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "#                       landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y,\n",
    "#                       landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].z])\n",
    "\n",
    "#     angle = np.arccos(np.dot(elbow-shoulder, wrist-elbow) /\n",
    "#                       (np.linalg.norm(elbow-shoulder) * np.linalg.norm(wrist-elbow)))\n",
    "\n",
    "#     angle_deg = np.degrees(angle)\n",
    "#     cv2.putText(overlay_image, f'Elbow Angle: {int(angle_deg)}', (10, text_y), \n",
    "#                 cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "#     text_y += 30\n",
    "\n",
    "#     ## Gait Analysis\n",
    "#     # Calculate stride length\n",
    "#     left_heel = landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value]\n",
    "#     right_heel = landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value]\n",
    "#     stride_length = np.linalg.norm([left_heel.x - right_heel.x, left_heel.y - right_heel.y, left_heel.z - right_heel.z])\n",
    "#     cv2.putText(overlay_image, f'Stride Length: {stride_length:.2f}', (10, text_y), \n",
    "#                 cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "#     text_y += 30\n",
    "\n",
    "#     ## Balance Analysis\n",
    "#     # Calculate center of mass\n",
    "#     com_x = sum([lmk.x for lmk in landmarks]) / len(landmarks)\n",
    "#     com_y = sum([lmk.y for lmk in landmarks]) / len(landmarks)\n",
    "#     com_z = sum([lmk.z for lmk in landmarks]) / len(landmarks)\n",
    "#     com = np.array([com_x, com_y, com_z])\n",
    "\n",
    "#     # Calculate distance from center of mass to left and right ankles\n",
    "#     left_ankle = landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value]\n",
    "#     right_ankle = landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value]\n",
    "#     left_ankle_dist = np.linalg.norm([left_ankle.x - com_x, left_ankle.y - com_y, left_ankle.z - com_z])\n",
    "#     right_ankle_dist = np.linalg.norm([right_ankle.x - com_x, right_ankle.y - com_y, right_ankle.z - com_z])\n",
    "\n",
    "#     # Calculate balance score\n",
    "#     balance_score = abs(left_ankle_dist - right_ankle_dist)\n",
    "#     cv2.putText(overlay_image, f'Balance Score: {balance_score:.2f}', (10, text_y), \n",
    "#                 cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "#     return overlay_image\n",
    "\n",
    "# def main():\n",
    "#     frame_count = 0\n",
    "\n",
    "#     # Create a resizable window\n",
    "#     cv2.namedWindow('Motion Capture', cv2.WINDOW_NORMAL)\n",
    "\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             # Restart the video\n",
    "#             # cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "#             # continue\n",
    "#             break\n",
    "\n",
    "#         # Convert the BGR image to RGB\n",
    "#         image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#         # Process the image and detect the pose\n",
    "#         results_pose = pose.process(image_rgb)\n",
    "\n",
    "#         if results_pose.pose_landmarks:\n",
    "#             # Draw the pose annotation on the image.\n",
    "#             mp_drawing.draw_landmarks(frame, results_pose.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "#             # Extract landmarks\n",
    "#             landmarks = results_pose.pose_landmarks.landmark\n",
    "\n",
    "#             # Draw 3D landmarks in the box\n",
    "#             draw_3d_landmarks_on_box(frame, landmarks, (frame.shape[1] - 210, 10))  # 10 px padding\n",
    "\n",
    "#             # Draw analytics overlay\n",
    "#             analytics_overlay = draw_analytics_overlay(landmarks)\n",
    "#             frame[10:10+analytics_overlay.shape[0], 10:10+analytics_overlay.shape[1]] = analytics_overlay\n",
    "\n",
    "#         # Write the frame to the output video file\n",
    "#         out.write(frame)\n",
    "\n",
    "#         # Display the resulting frame\n",
    "#         cv2.imshow('Motion Capture', frame)\n",
    "\n",
    "#         # Break loop on 'q' press\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "#         frame_count += 1\n",
    "\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ba42dae-d725-4ce7-9f75-20d0b9ceb6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install mediapipe\n",
    "!pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f236a326-5794-4446-ae09-c3cc1f16a5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize mediapipe pose and selfie segmentation\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_selfie_segmentation = mp.solutions.selfie_segmentation\n",
    "pose = mp_pose.Pose()\n",
    "selfie_segmentation = mp_selfie_segmentation.SelfieSegmentation(model_selection=1)\n",
    "\n",
    "# Initialize drawing utilities\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# ðŸŽ¨ Custom drawing specs for bold and deep-colored landmarks and connections\n",
    "landmark_spec = mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=6, circle_radius=4)\n",
    "connection_spec = mp_drawing.DrawingSpec(color=(0, 128, 255), thickness=4, circle_radius=2)\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(r\"C:\\Users\\PRAJES DAS\\Downloads\\video6.mp4\")\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output.mp4', fourcc, fps, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "def draw_3d_landmarks_on_box(image, landmarks, box_position):\n",
    "    h, w, _ = image.shape\n",
    "    box_w, box_h = 200, 200\n",
    "    box_x, box_y = box_position\n",
    "    \n",
    "    box_image = np.ones((box_h, box_w, 3), dtype=np.uint8) * np.array([252, 3, 161], dtype=np.uint8)\n",
    "    \n",
    "    for landmark in landmarks:\n",
    "        x = int(landmark.x * box_w)\n",
    "        y = int(landmark.y * box_h)\n",
    "        z = int(landmark.z * box_w)\n",
    "        cv2.circle(box_image, (x, y), 3, (3, 252, 206), -1)\n",
    "\n",
    "    image[box_y:box_y+box_h, box_x:box_x+box_w] = box_image\n",
    "\n",
    "def draw_analytics_overlay(landmarks, overlay_size=(300, 150)):\n",
    "    overlay_image = np.ones((overlay_size[1], overlay_size[0], 3), dtype=np.uint8) * np.array([252, 3, 161], dtype=np.uint8)\n",
    "    text_y = 20\n",
    "\n",
    "    # Posture Analysis\n",
    "    shoulder = np.array([landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].z])\n",
    "    elbow = np.array([landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y,\n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].z])\n",
    "    wrist = np.array([landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y,\n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].z])\n",
    "    \n",
    "    angle = np.arccos(np.dot(elbow - shoulder, wrist - elbow) /\n",
    "                      (np.linalg.norm(elbow - shoulder) * np.linalg.norm(wrist - elbow)))\n",
    "    angle_deg = np.degrees(angle)\n",
    "    \n",
    "    cv2.putText(overlay_image, f'Elbow Angle: {int(angle_deg)}', (10, text_y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    text_y += 30\n",
    "\n",
    "    # Gait Analysis\n",
    "    left_heel = landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value]\n",
    "    right_heel = landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value]\n",
    "    stride_length = np.linalg.norm([left_heel.x - right_heel.x, left_heel.y - right_heel.y, left_heel.z - right_heel.z])\n",
    "    cv2.putText(overlay_image, f'Stride Length: {stride_length:.2f}', (10, text_y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    text_y += 30\n",
    "\n",
    "    # Balance Analysis\n",
    "    com_x = sum([lmk.x for lmk in landmarks]) / len(landmarks)\n",
    "    com_y = sum([lmk.y for lmk in landmarks]) / len(landmarks)\n",
    "    com_z = sum([lmk.z for lmk in landmarks]) / len(landmarks)\n",
    "    com = np.array([com_x, com_y, com_z])\n",
    "\n",
    "    left_ankle = landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value]\n",
    "    right_ankle = landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value]\n",
    "    left_ankle_dist = np.linalg.norm([left_ankle.x - com_x, left_ankle.y - com_y, left_ankle.z - com_z])\n",
    "    right_ankle_dist = np.linalg.norm([right_ankle.x - com_x, right_ankle.y - com_y, right_ankle.z - com_z])\n",
    "    \n",
    "    balance_score = abs(left_ankle_dist - right_ankle_dist)\n",
    "    cv2.putText(overlay_image, f'Balance Score: {balance_score:.2f}', (10, text_y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    return overlay_image\n",
    "\n",
    "def main():\n",
    "    frame_count = 0\n",
    "    cv2.namedWindow('Motion Capture', cv2.WINDOW_NORMAL)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results_pose = pose.process(image_rgb)\n",
    "\n",
    "        if results_pose.pose_landmarks:\n",
    "            # ðŸ”¥ Use custom specs to draw bold motion lines\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                results_pose.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=landmark_spec,\n",
    "                connection_drawing_spec=connection_spec\n",
    "            )\n",
    "\n",
    "            landmarks = results_pose.pose_landmarks.landmark\n",
    "            draw_3d_landmarks_on_box(frame, landmarks, (frame.shape[1] - 210, 10))\n",
    "            analytics_overlay = draw_analytics_overlay(landmarks)\n",
    "            frame[10:10+analytics_overlay.shape[0], 10:10+analytics_overlay.shape[1]] = analytics_overlay\n",
    "\n",
    "        out.write(frame)\n",
    "        cv2.imshow('Motion Capture', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67f140d-2c42-4014-a472-bd7feca49e02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
